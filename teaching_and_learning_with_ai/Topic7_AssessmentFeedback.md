
# 7. Assessment and Feedback  
_Measuring learning and guiding improvement_

This step integrates previously designed assignments (quizzes, case studies, projects) and rubrics presented in Topic 4 with generative AI to enhance assessment strategies and feedback mechanisms.

## 7.1 Conduct Assessments Using Existing Assignment Types

**Task:**
Leverage previously developed assignments (quizzes, case studies, and projects) and embed generative AI to support delivery and evaluation.

*Instructional Prompt*
```
For each of the following assignments describe how generative AI can support their administration and analysis. Include one example prompt or tool for each assignment type. [Attach your assignments]
```

**Sample illustration** Matrix: Assignment Type Ã— GenAI Support (e.g., quiz auto-grading, case analysis generation, project feedback).

## 7.2 Generate Rubric-Based, Constructive Feedback

**Task:**
Use the rubrics created earlier (Topic 4) to automate high-quality feedback using generative AI.

*Role-Based Prompt*
```
You are an AI tutor grading a studentâ€™s AI-enhanced case study or teaching project. Based on this rubric (1. Pedagogical Soundness, 2. AI Integration, 3. Clarity of design), provide constructive feedback for each criterion and suggest improvements. [Attach the student's assignments]
```

**Sample illustration** Rubric feedback table: Criteria | Score | AI-generated Feedback

## 7.3 Use AI-Assisted Self- and Peer-Assessment

**Task:**
Integrate reflection and peer review workflows supported by AI-generated guiding questions.

*Few-Shot Prompt*
```
Examples of peer review prompts:
1. Evaluate how effectively AI was integrated into your peerâ€™s lesson design.
2. Suggest one way to improve ethical considerations in the use of AI.

Now generate a guided self-assessment checklist and three peer review prompts using the project rubric.
```

**Sample illustration** Checklist and review form interface with AI question generation icons.

## 7.4 Use AI for Feedback, Grading, and Originality Verification

**Task:**
Automate parts of the grading process while maintaining instructor oversight.

**Use Case 1: Finding Tools Available in the Literature**

*Zero-Shot Prompt*
```
List and briefly explain 3 tools that can be used to:
- Auto-grade AI-generated quiz responses
- Generate rubric-based feedback for student case studies
- Detect AI-generated plagiarism in teaching project submissions
Include benefits and limitations for each.
```

**Use Case 2: Using generic LLMs to Grade Essays**

*Role-Based Prompt with Embedded Instructional Prompts*
```
# Prompt to Grade Essays

You are an educational assistant tasked with grading essays. Perform the following tasks for a course on 'Teaching and Learning with AI', using student submissions. The tasks are: auto-grading quiz responses, generating rubric-based feedback for student case studies, and detecting AI-generated plagiarism in teaching project submissions. Follow the instructions for each task, ensuring consistency, accuracy, and actionable feedback.

## Task 1: Auto-Grade Quiz Responses
**Objective**: Grade quiz responses, including those potentially generated by AI, using a provided rubric.
**Inputs**:
- Quiz Question: [e.g., "How can AI support the 'Analyze' level of Bloomâ€™s Taxonomy in a classroom?"]
- Sample Responses: [e.g., Response 1: "AI can generate case studies for students to break down data patterns."; Response 2: "AI helps with analyzing stuff."]
- Rubric:
  - Content Accuracy (50%): Correctness of concepts.
  - Clarity (30%): Logical flow and readability.
  - Completeness (20%): Addresses all parts of the question.

**Instructions**:
1. Evaluate each response against the rubric.
2. Assign a score (0-100) with a breakdown (e.g., Content: 40/50, Clarity: 20/30, Completeness: 15/20).
3. Provide 1-2 sentences of feedback with improvement suggestions.
4. Return results in a table format:
   | Response | Content Accuracy (50) | Clarity (30) | Completeness (20) | Total Score (100) | Feedback |

## Task 2: Generate Rubric-Based Feedback for Student Case Studies
**Objective**: Provide detailed feedback on a case study submission using a rubric.
**Inputs**:
- Case Study Submission: [e.g., "I used an AI chatbot to teach students about computational complexity. It asked questions and gave feedback. Students found it helpful."]
- Rubric:
  - Relevance (40%): Alignment with course topics (e.g., computational complexity, AI pedagogy).
  - Depth of Analysis (30%): Insight into AI application in teaching.
  - Presentation (20%): Clarity and structure.
  - Innovation (10%): Creative use of AI tools.

**Instructions**:
1. Assess the submission against each rubric criterion, assigning scores out of 100 for each (e.g., Relevance: 60/100).
2. Calculate a total score as a weighted average.
3. Provide 2-3 sentences of feedback, including strengths, weaknesses, and suggestions.
4. Format the output as a table with scores and feedback:
   | Criterion | Score (out of 100) | Feedback |
   | Total Score | [Calculated] |

## Task 3: Detect AI-Generated Plagiarism in Teaching Project Submissions
**Objective**: Identify potential AI-generated content in project submissions.
**Inputs**:
- Project Submission: [e.g., "The application of AI in education enhances student engagement through personalized learning pathways. AI systems adapt content delivery based on individual performance metrics."]
- Detection Criteria: Look for signs of AI generation (e.g., overly polished phrasing, generic language, lack of personal voice, uniform structure).

**Instructions**:
1. Analyze the submission for signs of AI generation.
2. Assign a confidence score (0-100%) indicating the likelihood of AI generation.
3. Provide 1-2 sentences explaining your assessment and suggest next steps if plagiarism is suspected.
4. Return results in a table format:
   | Submission | Confidence Score (AI-Generated) | Assessment and Next Steps |

## Additional Notes
- Use course context where applicable.
- Ensure feedback is constructive and aligned with educational goals (e.g., improving student understanding of the topic).
- For Task 3, if the confidence score is high (>70%), recommend actions like requesting a revision or draft history by a specific date.
```

### Tools 1: Cograder.com or EssayGrader.ai (Essay Grading)
Cograder.com and EssayGrader.ai are AI tools designed to grade essays and help teachers to provide quality feedback in less time.

**Use Case 1:** To learn how Cograder or EssaGrader work try them by selecting the *Fill in with sample* in CoGrader (or copying this sample into EssayGrader) and analyze the output.

**Use Case 2:** If you have the case study delivered by a student, import or create the rubric into one of the tools to assess the assignment.

### Tool 2: SciSpace

**Use Case 1:** Using function *AI Detector* input the text or upload the PDF file with the content to be checked for originality.

### ðŸ–¼ Illustration:
Infographic of tools and risks (AI grading vs. human review).

---

## ðŸ“Š 5. Analyze Performance Data for Gaps and Misconceptions

### ðŸ“Œ Task:
Use GenAI to analyze results from quizzes, case studies, and projects to surface instructional needs.

### ðŸ§  Prompt (ðŸ”¹Chain-of-Thought Prompt):
```
Describe a process where you input quiz and project results into a generative AI tool. Ask the tool to identify performance trends and misconceptions across students. Summarize this data to prepare a follow-up review session.
```

### ðŸ–¼ Illustration:
Dashboard mockup showing: Score trends, AI-identified gaps, Suggested interventions.
